schema: '2.0'
stages:
  extract_dataset:
    cmd: python ./src/data/extract_dataset.py
    deps:
    - path: ./data/raw/zipped
      hash: md5
      md5: 2ac9e57fc0bc2d2a1a610a695529d479.dir
      size: 87295035
      nfiles: 2
    - path: ./src/data/extract_dataset.py
      hash: md5
      md5: 24f6687ca92d5922f222bd078e285c5e
      size: 1633
    outs:
    - path: ./data/raw/extracted
      hash: md5
      md5: 07dcb976ec534725901d50758a399273.dir
      size: 271383386
      nfiles: 2
  make_dataset:
    cmd: python ./src/data/make_dataset.py train.csv
    deps:
    - path: ./data/raw/extracted/train.csv
      hash: md5
      md5: e59c291a4b1c640f1dab33b89daa22e1
      size: 200589097
    - path: ./src/data/make_dataset.py
      hash: md5
      md5: a51d8af28054b6aa34063e8655fea4cb
      size: 3975
    params:
      params.yaml:
        make_dataset.random_state: 30
        make_dataset.test_size: 0.1
    outs:
    - path: ./data/interim/
      hash: md5
      md5: 7f670a515defe82553d40117c288d0a0.dir
      size: 195532592
      nfiles: 2
